#Wzorzec: https://www.r-bloggers.com/how-to-implement-random-forests-in-r/
#Feature selection: https://www.kaggle.com/nikhilesh87/easy-feature-selection-for-beginners-in-r
#Wniosek: Feature selection bierze najlepsze zmienne, a gdy chcemy uci¹æ wszystkie inne
#to model siê pogarsza i dostajemy wiêkszy b³¹d predykcji, => wincyj zmiennych => lepiej

#install.packages("randomForest") #odkomentuj aby zainstalowaæ pakiet
library(randomForest)


# Badamy parameter Dalc, 
d1=read.table("student-mat.csv",sep=",",header=TRUE)
d2=read.table("student-por.csv",sep=",",header=TRUE)
d1 <- d1[-c(28:29)] # wycinamy zmienn¹ Walc, jest ona bardzo skorelowana, to prawie to samo
d2 <- d2[-c(28:29)]

d3=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet", "Dalc"))



print(nrow(d3)) # 382 students

str(d3)
summary(d3)

set.seed(29790) # ustawianie ziarna doboru
train <- sample(nrow(d3), 0.70*nrow(d3), replace = FALSE) # stosunek zbioru trenuj¹cego do do waliduj¹cego
TrainSet <- d3[train,]
ValidSet <- d3[-train,]
summary(TrainSet)
summary(ValidSet)

levels(TrainSet$Dalc); # klasy który mamy przewidzieæ, 1 - ma³e spoÅ¼ycie %, 5 - du¿e
TrainSet$Dalc <- factor(TrainSet$Dalc); # zmieniamy wartoœci z ci¹g³ych na dysktetne ¿eby móc skorzystaæ z klasyfikacji, w przeciwnym wypadku byÅ‚aby regresja




##Tworzenie drzewka
# Create a Random Forest model with default parameters
model1 <- randomForest(Dalc ~ ., data = TrainSet, importance = TRUE)
#, classwt = c(8E1,80E1,100E1,200E1,8000E1))
#, classwt = c(80E1,20E1,10E1,8E1,8E1))
#, sampsize = c(180,40,12,6,5), replace=TRUE)
#generalnie mo¿na model boostowaæ poprzez dobór wag, czyli parametry classwt i sampsize ale œrednio mi to pomog³o, 
#moÅ¼na zrobiÄ‡ pÄ™tle co by sprawdzaÅ‚a Å›rÄ™dniÄ…, parametry te dobieramy dla wektora 5 elem. bo mamy 5 klas
#kod moe siÄ™ wywalaÄ‡ jeÅ›li ustawimy wiÄ™cej (sampsize) dla danej klasy niÅ¼ jestliczy dla niej zbÃ³r ternujÄ…cy
model1

# Predicting on train set
predTrain <- predict(model1, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$Dalc)

# Predicting on Validation set
predValid <- predict(model1, ValidSet, type = "class") #class and prob
# Checking classification accuracy
mean(predValid == ValidSet$Dalc) #dokÅ‚adnoÅ›Ä‡ jak dobrze nasz model przewiduje na niezaleÅ¼ym zbierze niÅ¼ trenujÄ…cy                  
table(predValid,ValidSet$Dalc)

#importance(model1)     #wykres waÅ¼noÅ›ci zmiennych, dodamy to w pkcie 5   
#varImpPlot(model1)  

##########################################################################
##1a)
# mtry evaluation
mTry_factor=c()
a <- (1:20)*0
y <- (1:20)*0
i=1
j=1

for(j in 1:5){
  i = 1
  for (i in 1:20) {
    model3 <- randomForest(Dalc ~ ., data = TrainSet, mtry = i, importance = TRUE)
    predValid <- predict(model3, ValidSet, type = "class")
    y[i] <- y[i] + mean(predValid == ValidSet$Dalc)
  }
}
y <- y/5

plot(1:20,y, main="Evaluation of mtry parameter",
     ylab="Accuracy", xlab="mtry value")

##########################################################################
##1b)
# ntree evaluation
nTree_factor=c()
a <- (1:10)*0
y <- (1:10)*0
x <- (1:10) * 100
i=1
j=1

for(j in 1:20){
  i = 1
  for (i in 1:10) {
    model3 <- randomForest(Dalc ~ ., data = TrainSet, ntree = x[i], importance = TRUE)
    predValid <- predict(model3, ValidSet, type = "class")
    y[i] <- y[i] + mean(predValid == ValidSet$Dalc)
  }
}

y <- y/20

plot(x,y, main="Evaluation of ntree parameter",
     ylab="Accuracy", xlab="ntree value")



##########################################################################
##Plan dziaÅ‚ania (robimy wszystko dla zmiennej Dalc - daily alcohal cons., w sumie Walc moÅ¼emy sobie darowaÄ‡, albo zrobiÄ‡ kopiuj wklej)
#1. SprawdziÄ‡ kaÅ¼dy parametr w pÄ™tli, jaka wartoÅ›Ä‡ nalepsza, czyli
# a) mtry (DONE)  -> najelszy wynik (1,2)
# b) ntree (DONE) -> najelszy wynik (400,500,600) trudno powiedzieÄ‡ ale w tych okolicach
################################TO DO##############################
# c) classwt (daÄ‡ proÃ³wnanie do braku tego parametru)
# d) samplesize (daÄ‡ proÃ³wnanie do braku tego parametru)
#2. SprawdziÄ‡ jaki stosunek zbioru trenujÄ…cego do walidujÄ…cego daje najlepszy rezultat
#3. SprawdziÄ‡ ile najlepszych zmiennych daje najlepszy rezultat
#4. SprawdziÄ‡ jaki seed daje najlepsze wyniki

#5. JeÅ›li juÅ¼ dobierzemy najlepsze parametry to moÅ¼na je wykorzystaÄ‡, puÅ›ciÄ‡
#jeszcze raz model z nimi, podaÄ‡ dokÅ‚adnoÅ›Ä‡ i narysowaÄ‡ wykres waÅ¼noÅ›ci zmiennych (importance)
#6. Dodatkowo moÅ¼na teÅ¼ dodaÄ‡ zmiennÄ… Dalc

##Jak to zrobiÄ‡
##Trzeba zrobiÄ‡ loop w loopie, sprawdzamy przedziaÅ‚ wartoÅ›ci, wszystko powararzamy N razy, 
#sumujemy do zmiennej i obliczmy Å›redniÄ…
#W przypadku 1. wystarczy tylko zmieniÄ‡ dodawaÄ‡ parametry w metodzie, w poostaÅ‚ych trzeba budowaÄ‡ teÅ¼ 
#caÅ‚y model od nowa

#TIP: Polecam zakomentowaÄ‡ moje pomiary, 1a i 1b to trochÄ™ zajmuje ich liczenie!!!!!!!

##########################################################################
##########################################################################
####WybÃ³r parametrÃ³w  (pkt 1)
model1 <- randomForest(Dalc ~ ., data = TrainSet, mtry = 5, ntree = 500, importance = TRUE)
#, classwt = c(8E1,80E1,100E1,200E1,8000E1))
#, classwt = c(80E1,20E1,10E1,8E1,8E1))
#, sampsize = c(180,40,12,6,5), replace=TRUE)
#generalnie moÅ¼na model boostowaÄ‡ poprzez dobÃ³r wag, czyli parametry classwt i sampsize ale Å›rednio mi to pomogÅ‚o, 
#moÅ¼na zrobiÄ‡ pÄ™tle co by sprawdzaÅ‚a Å›rÄ™dniÄ…, parametry te dobieramy dla wektora 5 elem. bo mamy 5 klas
#kod moe siÄ™ wywalaÄ‡ jeÅ›li ustawimy wiÄ™cej (sampsize) dla danej klasy niÅ¼ jestliczy dla niej zbÃ³r ternujÄ…cy

##########################################################################
##########################################################################
####WybÃ³r najistotniejszych zmiennych (pkt 2)
train <- sample(nrow(d3), 0.70*nrow(d3), replace = FALSE) # sotsunek zbioru trenujÄ…cego do do walidujÄ…cego

##########################################################################
##########################################################################
####WybÃ³r najistotniejszych zmiennych (pkt 3) - feature selection
#No. of cols in data frame
c <- ncol(TrainSet) #zliczamy zmienne kolumny
#Intializing the vector which will contain the p-values of all variables
pvalues <- numeric(c)
# Getting the p-values
for (i in 1:c)
{
  fit <- lm(TrainSet$Dalc ~ TrainSet[,i])  #sprawdzamy korelacjÄ™ przewidywanej zmiennej z konkretnÄ… zmiennÄ…
  summ <- summary(fit)
  pvalues[i] <- summ$coefficients[2,4]
}

#ord stores the column number in order of increasing p-value
ord <- order(pvalues) 
#Getting the column numbers for top 10 features with the predictor salerprice
ord <- ord[0:25]   #wybieramy liczbÄ™ najlepszych kolumn
Dalc <- TrainSet[,'Dalc']
TrainSet <- TrainSet[,ord]
TrainSet <- cbind(TrainSet,Dalc)
Dalc <- ValidSet[,'Dalc']
ValidSet <- ValidSet[,ord]
ValidSet <- cbind(ValidSet,Dalc)
##########################################################################
##########################################################################
####WybÃ³r seeda (pkt 4)
set.seed(29790) # ustawianie ziarna doboru


##########################################################################
##########################################################################
####Dodanie tych dodatkowych parametrÃ³w i generowanie nowego drzewa i wyliczeniem waÅ¼noÅ›ci (pkt 5)
#odkomentowaÄ‡, daje daje fajne wyniki
#importance(model1)     #wykres waÅ¼noÅ›ci zmiennych   
#varImpPlot(model1)  

##########################################################################
##########################################################################
####Dodanie zmiennej walc (pkt 6)
#usunÄ…Ä‡ poniÅ¼szy kod przy tworzeniu modelu
d1 <- d1[-c(28:29)] # wycinamy zmiennÄ… Walc, jest ona bardzo skorelowana, to prawie to samo
d2 <- d2[-c(28:29)]
